{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c51698b-32dd-46a6-92f1-6e9ded38f8ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/5] Loss: 0.633\n",
      "[2/5] Loss: 0.551\n",
      "[3/5] Loss: 0.491\n",
      "[4/5] Loss: 0.436\n",
      "[5/5] Loss: 0.385\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# (1, 0) => target labels 0+2\n",
    "# (0, 1) => target labels 1\n",
    "# (1, 1) => target labels 3\n",
    "train = []\n",
    "labels = []\n",
    "for i in range(100):\n",
    "    category = (np.random.choice([0, 1]), np.random.choice([0, 1]))\n",
    "    if category == (1, 0):\n",
    "        train.append([np.random.uniform(0.1, 1), 0])\n",
    "        labels.append([1, 0, 1])\n",
    "    if category == (0, 1):\n",
    "        train.append([0, np.random.uniform(0.1, 1)])\n",
    "        labels.append([0, 1, 0])\n",
    "    if category == (0, 0):\n",
    "        train.append([np.random.uniform(0.1, 1), np.random.uniform(0.1, 1)])\n",
    "        labels.append([0, 0, 1])\n",
    "\n",
    "class _classifier(nn.Module):\n",
    "    def __init__(self, nlabel):\n",
    "        super(_classifier, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, nlabel),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.main(input)\n",
    "\n",
    "nlabel = len(labels[0]) # => 3\n",
    "classifier = _classifier(nlabel)\n",
    "\n",
    "optimizer = optim.Adam(classifier.parameters())\n",
    "criterion = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    losses = []\n",
    "    for i, sample in enumerate(train):\n",
    "        inputv = Variable(torch.FloatTensor(sample)).view(1, -1)\n",
    "        labelsv = Variable(torch.FloatTensor(labels[i])).view(1, -1)\n",
    "        \n",
    "        output = classifier(inputv)\n",
    "        loss = criterion(output, labelsv)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses.append(loss.data.mean())\n",
    "    print('[%d/%d] Loss: %.3f' % (epoch+1, epochs, np.mean(losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40432e85-2b18-4fb6-89be-930e1f356bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d4a9a6-dcfa-473a-a954-e57310737e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.4840824864543315, 0.4987208654692753],\n",
       " [0.24690829347735213, 0],\n",
       " [0.7064577695474457, 0.8943571525384536],\n",
       " [0.1197492604242038, 0.622693650638203],\n",
       " [0.5660121045829768, 0],\n",
       " [0.6836690195686279, 0],\n",
       " [0.7245658395825295, 0.8611342125872714],\n",
       " [0.9387807326425673, 0.8193126092404551],\n",
       " [0, 0.11844149056678441],\n",
       " [0.5590932204456408, 0.8831955270241464],\n",
       " [0.3305706463018663, 0.8218178373544355],\n",
       " [0, 0.1023754219360227],\n",
       " [0.41122181523401713, 0.14750074582176348],\n",
       " [0.18908117938745106, 0.5487151837295198],\n",
       " [0.2265722309988835, 0.22978560944618925],\n",
       " [0.9408177722705535, 0.7461103140638746],\n",
       " [0.846011873194678, 0],\n",
       " [0.7281956312325628, 0.6493351523330145],\n",
       " [0, 0.8308760000526136],\n",
       " [0.3621443151291135, 0.15260164533259035],\n",
       " [0.945510716059024, 0.690756102008306],\n",
       " [0, 0.12509888585349271],\n",
       " [0.6425582569750473, 0],\n",
       " [0.3190872456567603, 0.843534717936507],\n",
       " [0, 0.33542447849415574],\n",
       " [0.5869930141099489, 0],\n",
       " [0.9375638044268498, 0.5970503993747057],\n",
       " [0.901812166857286, 0],\n",
       " [0, 0.3664071548478227],\n",
       " [0.9086470736077091, 0],\n",
       " [0.5404750501655631, 0],\n",
       " [0, 0.7855882568105299],\n",
       " [0.9253464936023097, 0],\n",
       " [0, 0.3064413604678924],\n",
       " [0.831279918027088, 0.7667573835258565],\n",
       " [0.8431106159159387, 0.7522312153212577],\n",
       " [0, 0.647673022970073],\n",
       " [0.6642947281226615, 0.9179435112604165],\n",
       " [0.9988179392941082, 0],\n",
       " [0.378809033321735, 0.4840460407610817],\n",
       " [0.253120049059137, 0.23246917972130118],\n",
       " [0, 0.5037049614210922],\n",
       " [0, 0.13286514416496215],\n",
       " [0.965828914456993, 0.2783236634736921],\n",
       " [0.7147805482499453, 0.8467315135306256],\n",
       " [0, 0.9895924750784889],\n",
       " [0.824246973542983, 0.24519490975901478],\n",
       " [0.9009275753376919, 0.6711221950955041],\n",
       " [0.7987171758803427, 0],\n",
       " [0.5228273902528582, 0.6863055790517831],\n",
       " [0.2611057465113639, 0],\n",
       " [0.37935095020392595, 0.4696462600991729],\n",
       " [0, 0.8077352231888371],\n",
       " [0, 0.5609537327393341],\n",
       " [0, 0.8679511545556098],\n",
       " [0, 0.22441823959617174],\n",
       " [0.9968302280470286, 0],\n",
       " [0.6598322460716877, 0.3963958509698341],\n",
       " [0.2035570451764171, 0],\n",
       " [0.8253965165076921, 0],\n",
       " [0.5706233727585425, 0.4927409772690663],\n",
       " [0.7262873255362621, 0],\n",
       " [0.1651798636977197, 0],\n",
       " [0, 0.9621453635481085],\n",
       " [0.9499441724076957, 0.4982497030848908],\n",
       " [0.6949635146164862, 0],\n",
       " [0, 0.6368780581918548],\n",
       " [0.9703442484438015, 0],\n",
       " [0.5193088382486551, 0.2747459868726434],\n",
       " [0.7103474928321803, 0],\n",
       " [0, 0.9755821421729105],\n",
       " [0.4261581999859885, 0],\n",
       " [0.34660704428800204, 0]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056d31be-3d02-498a-9ca0-53cfcd2e6817",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837f7dd0-8d82-428b-accf-ba21d58d0e8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
