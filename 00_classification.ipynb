{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5c60ed-759b-4221-93e1-716b73e04490",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "Example of a many-to-one problem using recurrent neural network. Following this [tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html).\n",
    "\n",
    "Let's try just like that.\n",
    "\n",
    "Required tasks:\n",
    "\n",
    "- load data\n",
    "- vectorize using one-hot encoding\n",
    "- write network class\n",
    "- setup training\n",
    "- train\n",
    "\n",
    "Next: \n",
    "- Find how to use a dataloader for inputs of varying size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "1d9d0f52-75c2-4900-9efc-17bf20809930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s, vocabulary):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in vocabulary\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64b9a3-9528-44ea-b7a9-85dffa0a3dcd",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Create dictionaries that map language->name and name->language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "87fca392-adfc-47d2-bfc9-23584fe71b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"./Data/names/names/*\")\n",
    "languages = [re.findall(r'./Data/names/names/(.*)\\.txt',t)[0] for t in file_list]\n",
    "lang2name = {}\n",
    "name2lang = {}\n",
    "# vocabulary = string.ascii_letters + \" .,;-'\"\n",
    "vocabulary = string.ascii_lowercase + \" .,;'\"\n",
    "\n",
    "max_seq_length = 0\n",
    "for lang, filename in zip(languages,file_list):\n",
    "    with open(filename) as file:\n",
    "        names = [l[:-1] for l in file.readlines()]\n",
    "        lang2name[lang] = names\n",
    "        for n in names:\n",
    "            name2lang[unicode_to_ascii(n, vocabulary)] = lang\n",
    "            max_seq_length = max(max_seq_length,len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "6690f183-0752-4a54-b3d1-d8ed4b206152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech 519\n",
      "German 724\n",
      "Arabic 2000\n",
      "Japanese 991\n",
      "Chinese 268\n",
      "Vietnamese 73\n",
      "Russian 9408\n",
      "French 277\n",
      "Irish 232\n",
      "English 3668\n",
      "Spanish 298\n",
      "Greek 203\n",
      "Italian 709\n",
      "Portuguese 74\n",
      "Scottish 100\n",
      "Dutch 297\n",
      "Korean 94\n",
      "Polish 139\n",
      "20074\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Czech': 1.5484187731571761,\n",
       " 'German': 1.2402453931395274,\n",
       " 'Arabic': 0.6299605249474367,\n",
       " 'Japanese': 1.006045362995162,\n",
       " 'Chinese': 2.4057110922637746,\n",
       " 'Vietnamese': 5.725122186823606,\n",
       " 'Russian': 0.22438911938367678,\n",
       " 'French': 2.353315492842517,\n",
       " 'Irish': 2.6485489876602135,\n",
       " 'English': 0.42044944350974206,\n",
       " 'Spanish': 2.241416117999791,\n",
       " 'Greek': 2.8951382557688383,\n",
       " 'Italian': 1.2576771673710465,\n",
       " 'Portuguese': 5.673427640281633,\n",
       " 'Scottish': 4.64158883361278,\n",
       " 'Dutch': 2.2464445359286023,\n",
       " 'Korean': 4.837059514655685,\n",
       " 'Polish': 3.7266917031512907}"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len()for key in lang2name.keys()\n",
    "total_names = 0\n",
    "lang2weights = {}\n",
    "for k, v in lang2name.items():\n",
    "    print(k, len(v))\n",
    "    total_names += len(v)\n",
    "    lang2weights[k] = 1.0/(len(v)**(1.0/1.5))\n",
    "print(total_names)\n",
    "for k, v in lang2weights.items():\n",
    "    lang2weights[k] *= 100#total_names\n",
    "#     lang2weights[k] = 1.0/lang2weights[k]\n",
    "lang2weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffe2aa-0c49-4a50-a918-b28e5fb98586",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "9c942f37-82a5-4cb2-bdac-6bd4eed9690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1])"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq2cat, vocabulary, categories, max_seq_length):\n",
    "        # seq2cat (dict) mapping input sequence and output category\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.input_sequences = list(seq2cat.keys())\n",
    "        self.output_category =  list(seq2cat.values())\n",
    "        self.categories = categories\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        self.vocab_length = len(self.vocabulary)\n",
    "        self.vocab2vec = {}\n",
    "        for i, vocab in enumerate(self.vocabulary):\n",
    "            self.vocab2vec[vocab] = torch.zeros((1,self.vocab_length),dtype=torch.float32)\n",
    "            self.vocab2vec[vocab][0,i] = 1\n",
    "            \n",
    "        num_categories = len(categories)\n",
    "        self.cat2vec = {}\n",
    "        for i, cat in enumerate(categories):\n",
    "            self.cat2vec[cat] = torch.tensor(i,dtype=torch.long)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def _get_seq_vec(self,sequence):\n",
    "        out = torch.zeros((self.max_seq_length,self.vocab_length))\n",
    "        for i, vec in enumerate(sequence.lower()):\n",
    "            out[i,:] = self.vocab2vec[vec]\n",
    "        return out\n",
    "#         return torch.cat([self.vocab2vec[vec] for vec in sequence.lower()],axis=0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         print(self.input_sequences[index])\n",
    "        input_sequence = self._get_seq_vec(self.input_sequences[index])\n",
    "        output_category = self.cat2vec[self.output_category[index]]\n",
    "        \n",
    "#         print(input_sequence)\n",
    "#         print(output_category.shape)\n",
    "        \n",
    "        return (input_sequence, output_category)\n",
    "    \n",
    "# Test    \n",
    "dataset = MyDataset(name2lang, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=1, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae3a5b-16f1-4187-83ec-35d70401d407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d36283-5583-4f92-96fc-804627d84e05",
   "metadata": {},
   "source": [
    "# Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "1405ad14-6aa9-487a-8c07-72f8d81fa83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self,vocab_length, num_categories,num_layers=1):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=vocab_length,\n",
    "                     hidden_size=num_categories,\n",
    "                     num_layers=num_layers, batch_first=True)\n",
    "#         self.rnn = nn.LSTM(input_size=vocab_length,\n",
    "#                      hidden_size=num_categories,\n",
    "#                      num_layers=1, batch_first=True)\n",
    "#         self.linear = nn.Linear()\n",
    "    def forward(self,X):\n",
    "        return self.rnn(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a0fd2-7a4a-43b3-a3b8-ab186d7252bf",
   "metadata": {},
   "source": [
    "# Initialize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "id": "673dfb2b-4e61-4278-959b-61c8315c00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(languages)\n",
    "vocab_length = len(vocabulary)\n",
    "model = MyRNN(vocab_length, num_categories,1)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2)\n",
    "dataset = MyDataset(name2lang, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=64, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "# inp.shape\n",
    "# cat.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc5d59-bc70-4109-8620-c27daa2af71b",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "id": "710c8649-dee6-4821-ac4c-9aaf84fd951c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000: loss=1.65e+00, accuracy=5.63e-01\n",
      "epoch 001: loss=1.65e+00, accuracy=5.75e-01\n",
      "epoch 002: loss=1.65e+00, accuracy=5.88e-01\n",
      "epoch 003: loss=1.65e+00, accuracy=6.13e-01\n",
      "epoch 004: loss=1.65e+00, accuracy=6.66e-01\n",
      "epoch 005: loss=1.64e+00, accuracy=6.75e-01\n",
      "epoch 006: loss=1.64e+00, accuracy=6.83e-01\n",
      "epoch 007: loss=1.64e+00, accuracy=6.89e-01\n",
      "epoch 008: loss=1.63e+00, accuracy=6.94e-01\n",
      "epoch 009: loss=1.63e+00, accuracy=6.97e-01\n"
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "for epoch in range(10):\n",
    "    n_data = len(dataloader)\n",
    "    loss_total = 0\n",
    "    accuracy = 0\n",
    "    for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "#         x_packed = pack_padded_sequence(x_embed, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        seq_len = inp.sum(dim=2).sum(dim=1).int()\n",
    "        inp = torch.nn.utils.rnn.pack_padded_sequence(inp,seq_len,batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        cat_out, h_out = model(inp)\n",
    "        cat_out, out_len = torch.nn.utils.rnn.pad_packed_sequence(cat_out, batch_first=True)\n",
    "\n",
    "        out = torch.cat([cat_out[sample,out_len[sample]-1,:].unsqueeze(0) for sample in range(cat_out.shape[0])],dim=0)\n",
    "\n",
    "        loss = loss_fn(out, ground_truth)\n",
    "#         with torch.no_grad():\n",
    "        loss_total += loss.mean()\n",
    "#         loss *= torch.tensor([lang2weights[languages[gt]] for gt in ground_truth])\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "#             pred = np.argmax(cat_out[:,-1,:],axis=1)\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "        \n",
    "#         loss_total += loss\n",
    "    loss_total /= len(dataloader)\n",
    "    accuracy /= len(dataloader)\n",
    "    print(f\"epoch {epoch:03d}: loss={loss_total:.2e}, accuracy={accuracy:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85988b00-47a9-47da-b2a8-6d692ee90fe1",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "id": "aff78345-e5af-4798-a3b5-3dccd42e26e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x129904430>"
      ]
     },
     "execution_count": 426,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = np.zeros((len(languages),len(languages)))\n",
    "for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "        seq_len = inp.sum(dim=2).sum(dim=1).int()\n",
    "        inp = torch.nn.utils.rnn.pack_padded_sequence(inp,seq_len,batch_first=True, enforce_sorted=False)\n",
    "        cat_out, h_out = model(inp)\n",
    "        cat_out, out_len = torch.nn.utils.rnn.pad_packed_sequence(cat_out, batch_first=True)\n",
    "        out = torch.cat([cat_out[sample,out_len[sample]-1,:].unsqueeze(0) for sample in range(cat_out.shape[0])],dim=0)\n",
    "        with torch.no_grad():\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            for p, gt in zip(pred, ground_truth):\n",
    "                conf_mat[gt,p] += 1.0\n",
    "#             accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "for i, l in enumerate(languages):\n",
    "    conf_mat[i,:] /= np.sum(conf_mat[i,:])#len(lang2name[l])\n",
    "    plt.imshow(conf_mat)      \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f459dde1-5e17-4fa9-a17b-0e3a14eb4fe3",
   "metadata": {},
   "source": [
    "So far it is just guessing English or Russian (the two most common classes for everything)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5969d3a-5f3d-4fe7-8216-dc550cf6460a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
