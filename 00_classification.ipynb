{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5c60ed-759b-4221-93e1-716b73e04490",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "Example of a many-to-one problem using recurrent neural network. Following this [tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html).\n",
    "\n",
    "Let's try just like that.\n",
    "\n",
    "Required tasks:\n",
    "\n",
    "- load data\n",
    "- vectorize using one-hot encoding\n",
    "- write network class\n",
    "- setup training\n",
    "- train\n",
    "\n",
    "Next: \n",
    "- Implement a test set and test function\n",
    "\n",
    "Note that the same name can be present in multiple languages. Therefore, cross correlation loss is not really adapted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9d0f52-75c2-4900-9efc-17bf20809930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s, vocabulary):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in vocabulary\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64b9a3-9528-44ea-b7a9-85dffa0a3dcd",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Create dictionaries that map language->name and name->language\n",
    "\n",
    "Certain files contain a lot of non-unique names. For example the \"Arabic.txt\" file contains 2000 lines but only 108 unique names. Here, we keep only the unique names. Note that the same name can appear in several languages. First, that means we can never achieve 100% accuracy. Second, we cannot store the examples as a name to language dictionary. Instead I'll use to lists: one for names and one for language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "87fca392-adfc-47d2-bfc9-23584fe71b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"./Data/names/names/*\")\n",
    "languages = [re.findall(r'./Data/names/names/(.*)\\.txt',t)[0] for t in file_list]\n",
    "lang2name = {}\n",
    "name2lang = {}\n",
    "# vocabulary = string.ascii_letters + \" .,;-'\"\n",
    "vocabulary = string.ascii_lowercase + \" .,;'\"\n",
    "\n",
    "max_seq_length = 0\n",
    "name_list = []\n",
    "lang_list = []\n",
    "for lang, filename in zip(languages,file_list):\n",
    "    with open(filename) as file:\n",
    "        names = [l[:-1] for l in file.readlines()]\n",
    "        names = list(set(names))\n",
    "        names = [unicode_to_ascii(n.lower(), vocabulary) for n in names]\n",
    "        lang2name[lang] = names\n",
    "        name_list += names\n",
    "        lang_list += [lang]*len(names)\n",
    "        for n in names:\n",
    "            max_seq_length = max(max_seq_length,len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "6690f183-0752-4a54-b3d1-d8ed4b206152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech 503 0.0019880715705765406\n",
      "German 706 0.00141643059490085\n",
      "Arabic 108 0.009259259259259259\n",
      "Japanese 990 0.00101010101010101\n",
      "Chinese 246 0.0040650406504065045\n",
      "Vietnamese 71 0.014084507042253521\n",
      "Russian 9342 0.00010704345964461572\n",
      "French 273 0.003663003663003663\n",
      "Irish 226 0.004424778761061947\n",
      "English 3668 0.0002726281352235551\n",
      "Spanish 296 0.0033783783783783786\n",
      "Greek 193 0.0051813471502590676\n",
      "Italian 701 0.0014265335235378032\n",
      "Portuguese 74 0.013513513513513514\n",
      "Scottish 100 0.01\n",
      "Dutch 286 0.0034965034965034965\n",
      "Korean 94 0.010638297872340425\n",
      "Polish 138 0.007246376811594203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Czech': 1.0000000000000093,\n",
       " 'German': 0.9999999999999932,\n",
       " 'Arabic': 1.0000000000000016,\n",
       " 'Japanese': 1.000000000000006,\n",
       " 'Chinese': 0.999999999999997,\n",
       " 'Vietnamese': 0.9999999999999991,\n",
       " 'Russian': 1.0000000000001081,\n",
       " 'French': 0.999999999999997,\n",
       " 'Irish': 1.0000000000000013,\n",
       " 'English': 0.9999999999999883,\n",
       " 'Spanish': 1.0000000000000042,\n",
       " 'Greek': 1.0000000000000024,\n",
       " 'Italian': 1.0000000000000053,\n",
       " 'Portuguese': 0.9999999999999986,\n",
       " 'Scottish': 1.0000000000000007,\n",
       " 'Dutch': 1.0000000000000062,\n",
       " 'Korean': 0.9999999999999983,\n",
       " 'Polish': 1.0000000000000013}"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len()for key in lang2name.keys()\n",
    "total_names = 0\n",
    "lang2weights = {}\n",
    "for k, v in lang2name.items():\n",
    "    print(k, len(v),  1.0/(len(v)))\n",
    "    total_names += len(v)\n",
    "    lang2weights[k] = 1.0/len(v)\n",
    "\n",
    "# Check that every class is weighted equally\n",
    "total_weights = {}\n",
    "for k, v in lang2weights.items(): # init\n",
    "    total_weights[k] = 0\n",
    "\n",
    "count = 0    \n",
    "for name, lang in zip(name_list, lang_list):\n",
    "    total_weights[lang] += lang2weights[lang]\n",
    "    count += 1\n",
    "total_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "e5335e07-90c1-4eba-8e4e-9c5b6cf55e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lang2name['Arabic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffe2aa-0c49-4a50-a918-b28e5fb98586",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "9c942f37-82a5-4cb2-bdac-6bd4eed9690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([19, 31])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq_list, cat_list, vocabulary, categories, max_seq_length):\n",
    "        # seq2cat (dict) mapping input sequence and output category\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.input_sequences = seq_list#list(seq2cat.keys())\n",
    "        self.output_category =  cat_list#list(seq2cat.values())\n",
    "        self.categories = categories\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        self.vocab_length = len(self.vocabulary)\n",
    "        self.vocab2vec = {}\n",
    "        for i, vocab in enumerate(self.vocabulary):\n",
    "            self.vocab2vec[vocab] = torch.zeros((1,self.vocab_length),dtype=torch.float32)\n",
    "            self.vocab2vec[vocab][0,i] = 1\n",
    "            \n",
    "        num_categories = len(categories)\n",
    "        self.cat2vec = {}\n",
    "        for i, cat in enumerate(categories):\n",
    "            self.cat2vec[cat] = torch.tensor(i,dtype=torch.long)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def _get_seq_vec(self,sequence):\n",
    "        # Pad \n",
    "        out = torch.zeros((self.max_seq_length,self.vocab_length))\n",
    "        for i, vec in enumerate(sequence.lower()):\n",
    "            out[i,:] = self.vocab2vec[vec]\n",
    "        return out\n",
    "#         Don't pad\n",
    "#         return torch.cat([self.vocab2vec[vec] for vec in sequence.lower()],axis=0)\n",
    "#         return torch.cat([self.vocab2vec[vec] for vec in sequence],axis=0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         print(self.input_sequences[index])\n",
    "        input_sequence = self._get_seq_vec(self.input_sequences[index])\n",
    "        output_category = self.cat2vec[self.output_category[index]]\n",
    "        \n",
    "#         print(input_sequence)\n",
    "#         print(output_category.shape)\n",
    "        \n",
    "        return (input_sequence, output_category)\n",
    "    \n",
    "# Test    \n",
    "dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=32, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "inp[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d36283-5583-4f92-96fc-804627d84e05",
   "metadata": {},
   "source": [
    "# Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "1405ad14-6aa9-487a-8c07-72f8d81fa83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self,vocab_length, num_categories,num_layers=1,hidden_size=128):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=vocab_length,\n",
    "                     hidden_size=hidden_size,#num_categories,\n",
    "                     num_layers=num_layers, batch_first=True, nonlinearity='relu')\n",
    "        self.linear = nn.Linear(hidden_size,num_categories)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "#         self.rnn = nn.LSTM(input_size=vocab_length,\n",
    "#                      hidden_size=num_categories,\n",
    "#                      num_layers=1, batch_first=True)\n",
    "#         self.linear = nn.Linear()\n",
    "    def forward(self,X):\n",
    "        # Pack padding to let the RNN know where to stop the sequence\n",
    "        seq_len = X.sum(dim=2).sum(dim=1).int()\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X,seq_len,batch_first=True, enforce_sorted=False)\n",
    "#         cat_out = model(inp, seq_len[-1])\n",
    "        \n",
    "        out, H = self.rnn(X)\n",
    "        out, out_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        \n",
    "        out = torch.cat([out[sample,out_len[sample]-1,:].view(1,1,-1) for sample in range(out.shape[0])],dim=0)\n",
    "\n",
    "#         out = out.view(out.shape[0],1,out.shape[1])\n",
    "#         print(out.shape)\n",
    "        out = self.linear(self.relu(out))\n",
    "\n",
    "        return out.view(out.shape[0],out.shape[2])\n",
    "    \n",
    "# # Test  \n",
    "# num_categories = len(languages)\n",
    "# vocab_length = len(vocabulary)\n",
    "# model = MyRNN(vocab_length, num_categories,1)\n",
    "# dataset = MyDataset(name2lang, vocabulary, languages, max_seq_length)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset,batch_size=1, shuffle=True)\n",
    "# inp = next(iter(dataloader))[0]\n",
    "# out = model(inp)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "c82cb5f7-8359-4d6a-aa23-b130a6367802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PyTorch tutorial\n",
    "class HisRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(HisRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # added\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, input):\n",
    "        hidden = torch.zeros(input.shape[0],self.hidden_size)\n",
    "        for i in range(input.shape[1]):\n",
    "            inp = input[:,i,:]\n",
    "            combined = torch.cat((inp, hidden), 1)\n",
    "            hidden = self.tanh(self.i2h(combined))\n",
    "            output = self.i2o(combined)\n",
    "#             output = self.softmax(output)\n",
    "\n",
    "        return output[:,-1,:] # only works for non-padded sequences\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = HisRNN(vocab_length, n_hidden, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "0ea9481d-6b2c-4683-b95e-5ddcc6f601e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Old\n",
    "# class MyRNN(nn.Module):\n",
    "#     def __init__(self,vocab_length, num_categories,num_layers=1):\n",
    "#         super(MyRNN,self).__init__()\n",
    "#         hidden_size = 128\n",
    "#         self.rnn = nn.RNN(input_size=vocab_length,\n",
    "#                      hidden_size=hidden_size,#num_categories,\n",
    "#                      num_layers=num_layers, batch_first=True)\n",
    "# #         self.rnn = nn.LSTM(input_size=vocab_length,\n",
    "# #                      hidden_size=num_categories,\n",
    "# #                      num_layers=1, batch_first=True)\n",
    "# #         self.linear = nn.Linear()\n",
    "#     def forward(self,X):\n",
    "#         return self.rnn(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a0fd2-7a4a-43b3-a3b8-ab186d7252bf",
   "metadata": {},
   "source": [
    "# Initialize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "673dfb2b-4e61-4278-959b-61c8315c00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(languages)\n",
    "vocab_length = len(vocabulary)\n",
    "model = MyRNN(vocab_length, num_categories,1)\n",
    "# model = HisRNN(vocab_length, n_hidden, num_categories)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-3)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=5e-3)\n",
    "# dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=32, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "# inp.shape\n",
    "# cat.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc5d59-bc70-4109-8620-c27daa2af71b",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "The dataset is imbalanced (9342 Russian examples, only 74 Portuguese). If we just run train over all the examples in the dataset the model just learns to predict everything as the one or two classes with the most examples (Russian and English). To overcome this difficulty we can choose between several strategy:\n",
    "\n",
    "- option 1: don't use a dataloader but iterate and choose one example per class at each iteration, or similarly, randomly sample a class and a sample from that class. That ensures that as many samples from each class is seen. The inconvenient is that samples from small classes are seen many times while samples for large classes are barely seen. This method is used [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) (see their randomTrainingExample function).\n",
    "- option 2: subsampling, i.e. create a new dataset at each epoch which contains as many examples from each class (randomly chosen)\n",
    "- option 3: use a dataloader (goes through every examples once per epoch) and weight the loss function according to the class, where the weight is $w=1/n_{class}$, where $n_{class}$ is the number of example in that class. I'll use this option here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "b3f80b0c-35ba-4781-a0cd-844535dd95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000: loss=1.87e+00, accuracy=4.34e-01\n",
      "epoch 001: loss=1.56e+00, accuracy=5.09e-01\n",
      "epoch 002: loss=1.48e+00, accuracy=5.36e-01\n",
      "epoch 003: loss=1.44e+00, accuracy=5.43e-01\n",
      "epoch 004: loss=1.38e+00, accuracy=5.64e-01\n",
      "epoch 005: loss=1.41e+00, accuracy=5.52e-01\n",
      "epoch 006: loss=1.34e+00, accuracy=5.72e-01\n",
      "epoch 007: loss=1.34e+00, accuracy=5.75e-01\n",
      "epoch 008: loss=1.31e+00, accuracy=5.83e-01\n",
      "epoch 009: loss=1.33e+00, accuracy=5.75e-01\n",
      "epoch 010: loss=1.35e+00, accuracy=5.80e-01\n",
      "epoch 011: loss=1.30e+00, accuracy=5.89e-01\n",
      "epoch 012: loss=1.27e+00, accuracy=5.93e-01\n",
      "epoch 013: loss=1.28e+00, accuracy=5.94e-01\n",
      "epoch 014: loss=1.27e+00, accuracy=5.95e-01\n",
      "epoch 015: loss=1.27e+00, accuracy=6.03e-01\n",
      "epoch 016: loss=1.28e+00, accuracy=5.93e-01\n",
      "epoch 017: loss=1.26e+00, accuracy=6.06e-01\n",
      "epoch 018: loss=1.27e+00, accuracy=6.07e-01\n",
      "epoch 019: loss=1.32e+00, accuracy=5.86e-01\n",
      "epoch 020: loss=1.29e+00, accuracy=5.96e-01\n",
      "epoch 021: loss=1.30e+00, accuracy=5.93e-01\n",
      "epoch 022: loss=1.26e+00, accuracy=6.00e-01\n",
      "epoch 023: loss=1.32e+00, accuracy=5.89e-01\n",
      "epoch 024: loss=1.29e+00, accuracy=5.99e-01\n",
      "epoch 025: loss=1.29e+00, accuracy=5.92e-01\n",
      "epoch 026: loss=1.30e+00, accuracy=5.90e-01\n",
      "epoch 027: loss=1.31e+00, accuracy=5.88e-01\n",
      "epoch 028: loss=1.26e+00, accuracy=6.03e-01\n",
      "epoch 029: loss=1.23e+00, accuracy=6.13e-01\n",
      "epoch 030: loss=1.28e+00, accuracy=5.97e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-280-3fc336d6096c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlang2weights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlanguages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Weighting to ensure each class carries as much in the loss calculation (fixes class imbalance)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "n_iter = len(dataloader)\n",
    "for epoch in range(100):\n",
    "    n_data = len(dataloader)\n",
    "    loss_total = 0\n",
    "    accuracy = 0\n",
    "    for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(inp)\n",
    "\n",
    "\n",
    "        loss = loss_fn(out, ground_truth)\n",
    "        loss_total += loss.mean()\n",
    "\n",
    "        loss *= torch.tensor([lang2weights[languages[gt]] for gt in ground_truth]) # Weighting to ensure each class carries as much in the loss calculation (fixes class imbalance)\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "\n",
    "    loss_total /= n_iter\n",
    "    accuracy /= n_iter\n",
    "    \n",
    "    print(f\"epoch {epoch:03d}: loss={loss_total:.2e}, accuracy={accuracy:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85988b00-47a9-47da-b2a8-6d692ee90fe1",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "aff78345-e5af-4798-a3b5-3dccd42e26e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x12cf47670>"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = np.zeros((len(languages),len(languages)))\n",
    "for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "#         seq_len = inp.sum(dim=2).sum(dim=1).int()\n",
    "#         inp = torch.nn.utils.rnn.pack_padded_sequence(inp,seq_len,batch_first=True, enforce_sorted=False)\n",
    "        out = model(inp)\n",
    "        with torch.no_grad():\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            for p, gt in zip(pred, ground_truth):\n",
    "                conf_mat[gt,p] += 1.0\n",
    "for i, l in enumerate(languages):\n",
    "    conf_mat[i,:] /= np.sum(conf_mat[i,:])#len(lang2name[l])\n",
    "    plt.imshow(conf_mat)      \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6d8d5-50d8-4a81-a4bd-546f3532cb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
