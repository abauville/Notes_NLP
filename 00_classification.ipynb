{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e5c60ed-759b-4221-93e1-716b73e04490",
   "metadata": {},
   "source": [
    "# Text classification\n",
    "\n",
    "Example of a many-to-one problem using recurrent neural network. Following this [tutorial](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html).\n",
    "\n",
    "Let's try just like that.\n",
    "\n",
    "Required tasks:\n",
    "\n",
    "- load data\n",
    "- vectorize using one-hot encoding\n",
    "- write network class\n",
    "- setup training\n",
    "- train\n",
    "\n",
    "Next: \n",
    "- Find how to use a dataloader for inputs of varying size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d9d0f52-75c2-4900-9efc-17bf20809930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import pandas\n",
    "import glob\n",
    "import re\n",
    "import string\n",
    "import unicodedata\n",
    "import matplotlib.pyplot as plt\n",
    "# Turn a Unicode string to plain ASCII, thanks to https://stackoverflow.com/a/518232/2809427\n",
    "def unicode_to_ascii(s, vocabulary):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "        and c in vocabulary\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe64b9a3-9528-44ea-b7a9-85dffa0a3dcd",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "## Create dictionaries that map language->name and name->language\n",
    "\n",
    "Certain files contain a lot of non-unique names. For example the \"Arabic.txt\" file contains 2000 lines but only 108 unique names. Here, we keep only the unique names. Note that the same name can appear in several languages. First, that means we can never achieve 100% accuracy. Second, we cannot store the examples as a name to language dictionary. Instead I'll use to lists: one for names and one for language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "87fca392-adfc-47d2-bfc9-23584fe71b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"./Data/names/names/*\")\n",
    "languages = [re.findall(r'./Data/names/names/(.*)\\.txt',t)[0] for t in file_list]\n",
    "lang2name = {}\n",
    "name2lang = {}\n",
    "vocabulary = string.ascii_letters + \" .,;-'\"\n",
    "# vocabulary = string.ascii_lowercase + \" .,;'\"\n",
    "\n",
    "max_seq_length = 0\n",
    "name_list = []\n",
    "lang_list = []\n",
    "for lang, filename in zip(languages,file_list):\n",
    "    with open(filename) as file:\n",
    "        names = [l[:-1] for l in file.readlines()]\n",
    "        names = list(set(names))\n",
    "        names = [unicode_to_ascii(n, vocabulary) for n in names]\n",
    "        lang2name[lang] = names\n",
    "        name_list += names\n",
    "#         print(lang)\n",
    "        lang_list += [lang]*len(names)\n",
    "        for n in names:\n",
    "#             name2lang[unicode_to_ascii(n, vocabulary)] = lang\n",
    "            max_seq_length = max(max_seq_length,len(n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae248028-f0d5-4b12-bbfe-f890e2f4cba5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "6690f183-0752-4a54-b3d1-d8ed4b206152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Czech 503 0.0019880715705765406\n",
      "German 706 0.00141643059490085\n",
      "Arabic 108 0.009259259259259259\n",
      "Japanese 990 0.00101010101010101\n",
      "Chinese 246 0.0040650406504065045\n",
      "Vietnamese 71 0.014084507042253521\n",
      "Russian 9342 0.00010704345964461572\n",
      "French 273 0.003663003663003663\n",
      "Irish 226 0.004424778761061947\n",
      "English 3668 0.0002726281352235551\n",
      "Spanish 296 0.0033783783783783786\n",
      "Greek 193 0.0051813471502590676\n",
      "Italian 701 0.0014265335235378032\n",
      "Portuguese 74 0.013513513513513514\n",
      "Scottish 100 0.01\n",
      "Dutch 286 0.0034965034965034965\n",
      "Korean 94 0.010638297872340425\n",
      "Polish 138 0.007246376811594203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Czech': 1.0000000000000093,\n",
       " 'German': 0.9999999999999932,\n",
       " 'Arabic': 1.0000000000000016,\n",
       " 'Japanese': 1.000000000000006,\n",
       " 'Chinese': 0.999999999999997,\n",
       " 'Vietnamese': 0.9999999999999991,\n",
       " 'Russian': 1.0000000000001081,\n",
       " 'French': 0.999999999999997,\n",
       " 'Irish': 1.0000000000000013,\n",
       " 'English': 0.9999999999999883,\n",
       " 'Spanish': 1.0000000000000042,\n",
       " 'Greek': 1.0000000000000024,\n",
       " 'Italian': 1.0000000000000053,\n",
       " 'Portuguese': 0.9999999999999986,\n",
       " 'Scottish': 1.0000000000000007,\n",
       " 'Dutch': 1.0000000000000062,\n",
       " 'Korean': 0.9999999999999983,\n",
       " 'Polish': 1.0000000000000013}"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len()for key in lang2name.keys()\n",
    "total_names = 0\n",
    "lang2weights = {}\n",
    "for k, v in lang2name.items():\n",
    "    print(k, len(v),  1.0/(len(v)))\n",
    "    total_names += len(v)\n",
    "    lang2weights[k] = 1.0/len(v)\n",
    "# print(total_names)\n",
    "# for k, v in lang2weights.items():\n",
    "#     lang2weights[k] *= total_names\n",
    "#     lang2weights[k] = 1.0/lang2weights[k]\n",
    "# display(lang2weights)\n",
    "\n",
    "\n",
    "# Check that every class is weighted equally\n",
    "total_weights = {}\n",
    "for k, v in lang2weights.items(): # init\n",
    "    total_weights[k] = 0\n",
    "\n",
    "count = 0    \n",
    "for name, lang in zip(name_list, lang_list):\n",
    "    total_weights[lang] += lang2weights[lang]\n",
    "    count += 1\n",
    "total_weights\n",
    "# count\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e5335e07-90c1-4eba-8e4e-9c5b6cf55e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "108"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lang2name['Arabic']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfffe2aa-0c49-4a50-a918-b28e5fb98586",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9c942f37-82a5-4cb2-bdac-6bd4eed9690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chinese',\n",
       " 'Italian',\n",
       " 'English',\n",
       " 'English',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'English',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Italian',\n",
       " 'Russian',\n",
       " 'English',\n",
       " 'French',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Greek',\n",
       " 'Chinese',\n",
       " 'Czech',\n",
       " 'Japanese',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Russian',\n",
       " 'Japanese',\n",
       " 'Italian',\n",
       " 'Russian',\n",
       " 'English']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, seq_list, cat_list, vocabulary, categories, max_seq_length):\n",
    "        # seq2cat (dict) mapping input sequence and output category\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.input_sequences = seq_list#list(seq2cat.keys())\n",
    "        self.output_category =  cat_list#list(seq2cat.values())\n",
    "        self.categories = categories\n",
    "        self.vocabulary = vocabulary\n",
    "        self.max_seq_length = max_seq_length\n",
    "        \n",
    "        self.vocab_length = len(self.vocabulary)\n",
    "        self.vocab2vec = {}\n",
    "        for i, vocab in enumerate(self.vocabulary):\n",
    "            self.vocab2vec[vocab] = torch.zeros((1,self.vocab_length),dtype=torch.float32)\n",
    "            self.vocab2vec[vocab][0,i] = 1\n",
    "            \n",
    "        num_categories = len(categories)\n",
    "        self.cat2vec = {}\n",
    "        for i, cat in enumerate(categories):\n",
    "            self.cat2vec[cat] = torch.tensor(i,dtype=torch.long)\n",
    "            \n",
    "            \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_sequences)\n",
    "    \n",
    "    def _get_seq_vec(self,sequence):\n",
    "        # Pad \n",
    "        out = torch.zeros((self.max_seq_length,self.vocab_length))\n",
    "        for i, vec in enumerate(sequence.lower()):\n",
    "            out[i,:] = self.vocab2vec[vec]\n",
    "        return out\n",
    "#         Don't pad\n",
    "#         return torch.cat([self.vocab2vec[vec] for vec in sequence.lower()],axis=0)\n",
    "#         return torch.cat([self.vocab2vec[vec] for vec in sequence],axis=0)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "#         print(self.input_sequences[index])\n",
    "        input_sequence = self._get_seq_vec(self.input_sequences[index])\n",
    "        output_category = self.cat2vec[self.output_category[index]]\n",
    "        \n",
    "#         print(input_sequence)\n",
    "#         print(output_category.shape)\n",
    "        \n",
    "        return (input_sequence, output_category)\n",
    "    \n",
    "# Test    \n",
    "dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=32, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "inp[0].shape\n",
    "\n",
    "# np.argwhere(inp[0].numpy())[:,1]\n",
    "# cat\n",
    "[languages[i] for i in cat]\n",
    "# dataset.vocab2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aae3a5b-16f1-4187-83ec-35d70401d407",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d36283-5583-4f92-96fc-804627d84e05",
   "metadata": {},
   "source": [
    "# Define neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "1405ad14-6aa9-487a-8c07-72f8d81fa83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRNN(nn.Module):\n",
    "    def __init__(self,vocab_length, num_categories,num_layers=1,hidden_size=128):\n",
    "        super(MyRNN,self).__init__()\n",
    "        self.rnn = nn.RNN(input_size=vocab_length,\n",
    "                     hidden_size=hidden_size,#num_categories,\n",
    "                     num_layers=num_layers, batch_first=True, nonlinearity='relu')\n",
    "        self.linear = nn.Linear(hidden_size,num_categories)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "#         self.rnn = nn.LSTM(input_size=vocab_length,\n",
    "#                      hidden_size=num_categories,\n",
    "#                      num_layers=1, batch_first=True)\n",
    "#         self.linear = nn.Linear()\n",
    "    def forward(self,X):\n",
    "        # Pack padding to let the RNN know where to stop the sequence\n",
    "        seq_len = X.sum(dim=2).sum(dim=1).int()\n",
    "        X = torch.nn.utils.rnn.pack_padded_sequence(X,seq_len,batch_first=True, enforce_sorted=False)\n",
    "#         cat_out = model(inp, seq_len[-1])\n",
    "        \n",
    "        out, H = self.rnn(X)\n",
    "        out, out_len = torch.nn.utils.rnn.pad_packed_sequence(out, batch_first=True)\n",
    "        \n",
    "        out = torch.cat([out[sample,out_len[sample]-1,:].view(1,1,-1) for sample in range(out.shape[0])],dim=0)\n",
    "\n",
    "#         out = out.view(out.shape[0],1,out.shape[1])\n",
    "#         print(out.shape)\n",
    "        out = self.linear(self.relu(out))\n",
    "\n",
    "        return out.view(out.shape[0],out.shape[2])\n",
    "    \n",
    "# # Test  \n",
    "# num_categories = len(languages)\n",
    "# vocab_length = len(vocabulary)\n",
    "# model = MyRNN(vocab_length, num_categories,1)\n",
    "# dataset = MyDataset(name2lang, vocabulary, languages, max_seq_length)\n",
    "# dataloader = torch.utils.data.DataLoader(dataset,batch_size=1, shuffle=True)\n",
    "# inp = next(iter(dataloader))[0]\n",
    "# out = model(inp)\n",
    "# out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "c82cb5f7-8359-4d6a-aa23-b130a6367802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From PyTorch tutorial\n",
    "class HisRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(HisRNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.i2h = nn.Linear(input_size + hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(input_size + hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        # added\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, input):\n",
    "        hidden = torch.zeros(input.shape[0],self.hidden_size)\n",
    "        for i in range(input.shape[1]):\n",
    "            inp = input[:,i,:]\n",
    "            combined = torch.cat((inp, hidden), 1)\n",
    "            hidden = self.tanh(self.i2h(combined))\n",
    "            output = self.i2o(combined)\n",
    "#             output = self.softmax(output)\n",
    "\n",
    "        return output[:,-1,:] # only works for non-padded sequences\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "n_hidden = 128\n",
    "rnn = HisRNN(vocab_length, n_hidden, num_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "0ea9481d-6b2c-4683-b95e-5ddcc6f601e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Old\n",
    "# class MyRNN(nn.Module):\n",
    "#     def __init__(self,vocab_length, num_categories,num_layers=1):\n",
    "#         super(MyRNN,self).__init__()\n",
    "#         hidden_size = 128\n",
    "#         self.rnn = nn.RNN(input_size=vocab_length,\n",
    "#                      hidden_size=hidden_size,#num_categories,\n",
    "#                      num_layers=num_layers, batch_first=True)\n",
    "# #         self.rnn = nn.LSTM(input_size=vocab_length,\n",
    "# #                      hidden_size=num_categories,\n",
    "# #                      num_layers=1, batch_first=True)\n",
    "# #         self.linear = nn.Linear()\n",
    "#     def forward(self,X):\n",
    "#         return self.rnn(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2a0fd2-7a4a-43b3-a3b8-ab186d7252bf",
   "metadata": {},
   "source": [
    "# Initialize training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "673dfb2b-4e61-4278-959b-61c8315c00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_categories = len(languages)\n",
    "vocab_length = len(vocabulary)\n",
    "model = MyRNN(vocab_length, num_categories,1)\n",
    "# model = HisRNN(vocab_length, n_hidden, num_categories)\n",
    "loss_fn = nn.CrossEntropyLoss(reduction='none')\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=1e-2)\n",
    "# optimizer = torch.optim.SGD(model.parameters(),lr=5e-3)\n",
    "# dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataset = MyDataset(name_list, lang_list, vocabulary, languages, max_seq_length)\n",
    "dataloader = torch.utils.data.DataLoader(dataset,batch_size=32, shuffle=True)\n",
    "inp, cat = next(iter(dataloader))\n",
    "# inp.shape\n",
    "# cat.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "0b70525c-a74d-4ae8-bcfd-b9dba5a09475",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Czech': 0.0019880715705765406,\n",
       " 'German': 0.00141643059490085,\n",
       " 'Arabic': 0.009259259259259259,\n",
       " 'Japanese': 0.00101010101010101,\n",
       " 'Chinese': 0.0040650406504065045,\n",
       " 'Vietnamese': 0.014084507042253521,\n",
       " 'Russian': 0.00010704345964461572,\n",
       " 'French': 0.003663003663003663,\n",
       " 'Irish': 0.004424778761061947,\n",
       " 'English': 0.0002726281352235551,\n",
       " 'Spanish': 0.0033783783783783786,\n",
       " 'Greek': 0.0051813471502590676,\n",
       " 'Italian': 0.0014265335235378032,\n",
       " 'Portuguese': 0.013513513513513514,\n",
       " 'Scottish': 0.01,\n",
       " 'Dutch': 0.0034965034965034965,\n",
       " 'Korean': 0.010638297872340425,\n",
       " 'Polish': 0.007246376811594203}"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lang2weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decc5d59-bc70-4109-8620-c27daa2af71b",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "The dataset is imbalanced (9342 Russian examples, only 74 Portuguese). If we just run train over all the examples in the dataset the model just learns to predict everything as the one or two classes with the most examples (Russian and English). To overcome this difficulty we can choose between several strategy:\n",
    "\n",
    "- option 1: don't use a dataloader but iterate and choose one example per class at each iteration, or similarly, randomly sample a class and a sample from that class. That ensures that as many samples from each class is seen. The inconvenient is that samples from small classes are seen many times while samples for large classes are barely seen. This method is used [here](https://pytorch.org/tutorials/intermediate/char_rnn_classification_tutorial.html) (see their randomTrainingExample function).\n",
    "- option 2: use a dataloader (goes through every examples once per epoch) and weight the loss function according to the class, where the weight is $w=1/n_{class}$, where $n_{class}$ is the number of example in that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "f163820e-8656-4db9-9502-63b9729ffbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab2vec = {}\n",
    "for i, vocab in enumerate(vocabulary):\n",
    "    vocab2vec[vocab] = torch.zeros((1,vocab_length),dtype=torch.float32)\n",
    "    vocab2vec[vocab][0,i] = 1\n",
    "            \n",
    "def get_seq_vec(sequence):\n",
    "    mat = torch.zeros((max_seq_length,vocab_length))\n",
    "    for i, letter in enumerate(sequence.lower()):\n",
    "        mat[i,:] = vocab2vec[letter]\n",
    "    return mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "710c8649-dee6-4821-ac4c-9aaf84fd951c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000: loss=1.59e+00, accuracy=4.80e-01\n",
      "epoch 001: loss=1.36e+00, accuracy=5.59e-01\n",
      "epoch 002: loss=1.22e+00, accuracy=5.99e-01\n",
      "epoch 003: loss=1.17e+00, accuracy=6.19e-01\n",
      "epoch 004: loss=1.14e+00, accuracy=6.28e-01\n",
      "epoch 005: loss=1.16e+00, accuracy=6.30e-01\n",
      "epoch 006: loss=1.14e+00, accuracy=6.35e-01\n",
      "epoch 007: loss=1.10e+00, accuracy=6.46e-01\n",
      "epoch 008: loss=1.14e+00, accuracy=6.32e-01\n",
      "epoch 009: loss=1.14e+00, accuracy=6.30e-01\n",
      "epoch 010: loss=1.07e+00, accuracy=6.49e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-256-bc58cfe2948d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#             pred = np.argmax(cat_out[:,-1,:],axis=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/autograd/profiler.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_function_enter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# optimizer = torch.optim.Adam(model.parameters(),lr=1e-3)\n",
    "\n",
    "for epoch in range(100):\n",
    "    n_data = len(dataloader)\n",
    "    loss_total = 0\n",
    "    accuracy = 0\n",
    "#     for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "    ground_truth = torch.arange(0,len(languages))\n",
    "    n_iter = 1000\n",
    "    for i in range(1000):\n",
    "        names = [lang2name[lang][int(np.random.rand()*len(lang2name[lang]))] for lang in languages]\n",
    "        inp = torch.cat([get_seq_vec(n).unsqueeze(0) for n in names],dim=0)\n",
    "#         print(list(zip(names,languages)))\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(inp)\n",
    "\n",
    "\n",
    "        loss = loss_fn(out, ground_truth)\n",
    "#         with torch.no_grad():\n",
    "        loss_total += loss.mean()\n",
    "#         print(loss)\n",
    "        \n",
    "#         loss *= torch.tensor([lang2weights[languages[gt]] for gt in ground_truth])#**(1.0/1.5)*100.0\n",
    "#         print(loss)\n",
    "#         print([languages[gt] for gt in ground_truth])\n",
    "#         break\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "#             pred = np.argmax(cat_out[:,-1,:],axis=1)\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "        \n",
    "#         loss_total += loss\n",
    "#     loss_total /= len(dataloader)\n",
    "#     accuracy /= len(dataloader)\n",
    "    \n",
    "    loss_total /= n_iter\n",
    "    accuracy /= n_iter\n",
    "    \n",
    "    print(f\"epoch {epoch:03d}: loss={loss_total:.2e}, accuracy={accuracy:.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "b3f80b0c-35ba-4781-a0cd-844535dd95ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 000: loss=2.40e+00, accuracy=3.74e-01\n",
      "epoch 001: loss=1.87e+00, accuracy=4.48e-01\n",
      "epoch 002: loss=1.70e+00, accuracy=4.88e-01\n",
      "epoch 003: loss=1.60e+00, accuracy=5.17e-01\n",
      "epoch 004: loss=1.53e+00, accuracy=5.32e-01\n",
      "epoch 005: loss=1.49e+00, accuracy=5.42e-01\n",
      "epoch 006: loss=1.43e+00, accuracy=5.52e-01\n",
      "epoch 007: loss=1.42e+00, accuracy=5.56e-01\n",
      "epoch 008: loss=1.38e+00, accuracy=5.60e-01\n",
      "epoch 009: loss=1.35e+00, accuracy=5.67e-01\n",
      "epoch 010: loss=1.32e+00, accuracy=5.76e-01\n",
      "epoch 011: loss=1.31e+00, accuracy=5.81e-01\n",
      "epoch 012: loss=1.28e+00, accuracy=5.90e-01\n",
      "epoch 013: loss=1.25e+00, accuracy=6.00e-01\n",
      "epoch 014: loss=1.23e+00, accuracy=6.07e-01\n",
      "epoch 015: loss=1.22e+00, accuracy=6.06e-01\n",
      "epoch 016: loss=1.22e+00, accuracy=6.11e-01\n",
      "epoch 017: loss=1.19e+00, accuracy=6.16e-01\n",
      "epoch 018: loss=1.18e+00, accuracy=6.20e-01\n",
      "epoch 019: loss=1.15e+00, accuracy=6.23e-01\n",
      "epoch 020: loss=1.15e+00, accuracy=6.30e-01\n",
      "epoch 021: loss=1.13e+00, accuracy=6.38e-01\n",
      "epoch 022: loss=1.12e+00, accuracy=6.38e-01\n",
      "epoch 023: loss=1.09e+00, accuracy=6.48e-01\n",
      "epoch 024: loss=1.09e+00, accuracy=6.48e-01\n",
      "epoch 025: loss=1.07e+00, accuracy=6.54e-01\n",
      "epoch 026: loss=1.05e+00, accuracy=6.60e-01\n",
      "epoch 027: loss=1.03e+00, accuracy=6.66e-01\n",
      "epoch 028: loss=1.02e+00, accuracy=6.70e-01\n",
      "epoch 029: loss=1.02e+00, accuracy=6.70e-01\n",
      "epoch 030: loss=9.88e-01, accuracy=6.83e-01\n",
      "epoch 031: loss=9.89e-01, accuracy=6.79e-01\n",
      "epoch 032: loss=9.68e-01, accuracy=6.89e-01\n",
      "epoch 033: loss=9.80e-01, accuracy=6.88e-01\n",
      "epoch 034: loss=9.79e-01, accuracy=6.88e-01\n",
      "epoch 035: loss=9.57e-01, accuracy=6.92e-01\n",
      "epoch 036: loss=9.17e-01, accuracy=7.07e-01\n",
      "epoch 037: loss=9.28e-01, accuracy=7.02e-01\n",
      "epoch 038: loss=9.00e-01, accuracy=7.14e-01\n",
      "epoch 039: loss=8.89e-01, accuracy=7.16e-01\n",
      "epoch 040: loss=8.92e-01, accuracy=7.18e-01\n",
      "epoch 041: loss=8.65e-01, accuracy=7.23e-01\n",
      "epoch 042: loss=8.69e-01, accuracy=7.25e-01\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-261-d408c633031c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-593c0ac5da32>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;31m#         print(self.input_sequences[index])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0minput_sequence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_seq_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_sequences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0moutput_category\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_category\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-144-593c0ac5da32>\u001b[0m in \u001b[0;36m_get_seq_vec\u001b[0;34m(self, sequence)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_seq_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvec\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msequence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab2vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m#         Don't pad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(),lr=5e-4)\n",
    "n_iter = len(dataloader)\n",
    "for epoch in range(100):\n",
    "    n_data = len(dataloader)\n",
    "    loss_total = 0\n",
    "    accuracy = 0\n",
    "    for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        out = model(inp)\n",
    "\n",
    "\n",
    "        loss = loss_fn(out, ground_truth)\n",
    "#         with torch.no_grad():\n",
    "        loss_total += loss.mean()\n",
    "#         print(loss)\n",
    "        \n",
    "        loss *= torch.tensor([lang2weights[languages[gt]] for gt in ground_truth])#*100.0#**(1.0/1.5)*100.0\n",
    "#         print(loss)\n",
    "#         print([languages[gt] for gt in ground_truth])\n",
    "#         break\n",
    "        loss = loss.mean()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        with torch.no_grad():\n",
    "#             pred = np.argmax(cat_out[:,-1,:],axis=1)\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "        \n",
    "#         loss_total += loss\n",
    "#     loss_total /= len(dataloader)\n",
    "#     accuracy /= len(dataloader)\n",
    "    \n",
    "    loss_total /= n_iter\n",
    "    accuracy /= n_iter\n",
    "    \n",
    "    print(f\"epoch {epoch:03d}: loss={loss_total:.2e}, accuracy={accuracy:.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85988b00-47a9-47da-b2a8-6d692ee90fe1",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "aff78345-e5af-4798-a3b5-3dccd42e26e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x12bd549d0>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_mat = np.zeros((len(languages),len(languages)))\n",
    "for i, (inp, ground_truth) in enumerate(dataloader):\n",
    "#         seq_len = inp.sum(dim=2).sum(dim=1).int()\n",
    "#         inp = torch.nn.utils.rnn.pack_padded_sequence(inp,seq_len,batch_first=True, enforce_sorted=False)\n",
    "        out = model(inp)\n",
    "#         cat_out, out_len = torch.nn.utils.rnn.pad_packed_sequence(cat_out, batch_first=True)\n",
    "#         out = torch.cat([cat_out[sample,out_len[sample]-1,:].unsqueeze(0) for sample in range(cat_out.shape[0])],dim=0)\n",
    "        with torch.no_grad():\n",
    "            pred = np.argmax(out,axis=1)\n",
    "            for p, gt in zip(pred, ground_truth):\n",
    "                conf_mat[gt,p] += 1.0\n",
    "#             accuracy += (pred == ground_truth).sum()/len(ground_truth)\n",
    "for i, l in enumerate(languages):\n",
    "    conf_mat[i,:] /= np.sum(conf_mat[i,:])#len(lang2name[l])\n",
    "    plt.imshow(conf_mat)      \n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c5969d3a-5f3d-4fe7-8216-dc550cf6460a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'Czech'),\n",
       " (1, 'German'),\n",
       " (2, 'Arabic'),\n",
       " (3, 'Japanese'),\n",
       " (4, 'Chinese'),\n",
       " (5, 'Vietnamese'),\n",
       " (6, 'Russian'),\n",
       " (7, 'French'),\n",
       " (8, 'Irish'),\n",
       " (9, 'English'),\n",
       " (10, 'Spanish'),\n",
       " (11, 'Greek'),\n",
       " (12, 'Italian'),\n",
       " (13, 'Portuguese'),\n",
       " (14, 'Scottish'),\n",
       " (15, 'Dutch'),\n",
       " (16, 'Korean'),\n",
       " (17, 'Polish')]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(languages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d6d8d5-50d8-4a81-a4bd-546f3532cb02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
